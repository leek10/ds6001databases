{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 6: Creating and Connecting to Databases\n",
    "## DS 6001: Practice and Application of Data Science\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "**Please note: you will not be able to use Rivanna for this lab as Rivanna is not set up to work with Docker or with Databases. If you need help getting your local system running, please let me know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0 [No points, no need to write anything here for any of the following parts, but do it anyway!]\n",
    "Databases require a lot of external software. The good news is that there are excellent free and open source options to do very advanced work with databases. The bad news is that each piece of additional software comes with its own complications. This problem will guide you through the installation steps for the software you need to run database systems on your computer, document those databases, and connect to them through Python with (fingers crossed) as few problems as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Use `pip` to install the following Python packages on your system:\n",
    "```\n",
    "mysql-connector-python\n",
    "psycopg\n",
    "pymongo\n",
    "sqlalchemy\n",
    "wget\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "With the exception of SQlite, database systems run as external software that must be installed and run on your computer. To make the installation steps easier, you will need some configuration files that I wrote and saved in a GitHub repository. Open your terminal and use the `cd` command to navigate to the folder in your computer where you want to work. Then type\n",
    "```\n",
    "git clone https://github.com/jkropko/ds6001databases\n",
    "```\n",
    "If this command works, it will create a new directory within your current folder called \"ds6001databases\".\n",
    "\n",
    "* Check that this folder exists and contains the following files: LICENSE, README.md, compose.yaml, db_tests.ipynb, and requirements.txt\n",
    "* Save the notebook file you will be using for your Lab 6 work inside the \"ds6001databases\" folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "We will be using a system called Docker to work with databases. Docker is the most commonly used platform for working with **containers**. While we will not be delving into the topic of containerization in this course, a container is space in your computer's memory that is set apart from the rest of your computer. We can act as if the container is an entirely new computer, and inside the container we can change the operating system and install other software external to Python, such as database management systems. We can use a container to run Windows on a Mac, or vice versa, or Linux on any system. By far the easiest way to run MySQL, PostgreSQL, and MongoDB is through Docker containers. \n",
    "\n",
    "You will need to install Docker Desktop on your computer. Go to https://www.docker.com/products/docker-desktop/ and click on the Download button, making sure the operating system listed matches the operating system of your computer.\n",
    "\n",
    "Once Docker Desktop is installed, find the Docker Desktop program on your computer and run it.\n",
    "\n",
    "To confirm that Docker Desktop is running, open a terminal and type `docker help`. If you see documentation that begins\n",
    "```\n",
    "Usage:  docker [OPTIONS] COMMAND\n",
    "\n",
    "A self-sufficient runtime for containers\n",
    "```\n",
    "then you are all set. If you see an error that Docker is not found, then the Docker Desktop client was not installed properly, so you should try downloading and installing it from the website again. If you receive a message that the Docker daemon is not running, then Docker is installed but is not running. Find the Docker Desktop executable on your computer and click it to get Docker running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part d\n",
    "Inside your \"ds6001databases\" folder, create a .env file. On a Mac, type `touch .env` then `open .env` to create and open the file. On Windows, open a new file on Notepad and go to \"Save As\", then save it in your \"ds6001databases\" folder -- make sure to set \"File As Type\" to \"All files\" and name the file \".env\".\n",
    "\n",
    "Inside the .env file you need to choose passwords for the MySQL, PostgreSQL, and MongoDB databases, so type\n",
    "```\n",
    "MYSQL_ROOT_PASSWORD=redlobstercheddarbiscuits\n",
    "POSTGRES_PASSWORD=outbackbloominonion\n",
    "MONGO_INITDB_ROOT_PASSWORD=olivegardenunlimitedbreadsticks\n",
    "MONGO_INITDB_ROOT_USERNAME=mongo\n",
    "mongo_init_db = mongodb\n",
    "MYSQL_DATABASE=mysql\n",
    "```\n",
    "Change the passwords on the first three lines to whatever you want, but DON'T USE THE @ SYMBOL as that will cause problems. Leave the fourth, fifth, and sixth lines alone, as well as the names of each environmental variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part e\n",
    "In the terminal, make sure you are in the \"ds6001databases\" folder (you can check by typing `pwd`. If not, then use `cd` to navigate to the \"ds6001databases\" folder). Then type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "This command launches all of the databases. If successful, you will see a long stream of output with messages that begin `ds6001databases-postgres-1`, `ds6001databases-mysql-1`, and `ds6001databases-mongo-1`. If not, we will need to debug together, but the issue likely has to do with something preventing parts a, b, c, or d from being completed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part f\n",
    "To confirm that the databases are running on your system, open the \"db_tests.ipynb\" notebook file, which should be saved in you \"ds6001databases\" folder. Run everything in this notebook and make sure there are no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part g\n",
    "In addition to the databases, we will be using dbdocs.io to create documentation for our databases and post them online with a stable URL. But to get dbdocs running, you first need to install NodeJS on your computer: https://nodejs.org/en\n",
    "\n",
    "Then to install dbdocs, follow the instructions here: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part h\n",
    "Finally, create a notebook inside your \"ds6001databases\" folder for your work on this lab. Import the following libraries, and load the `.env` file where you store your passwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\leeka\\miniconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import mysql.connector\n",
    "import psycopg\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "mongo_init_db = os.getenv('mongo_init_db')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "**This problem requires you to create Markdown tables** \n",
    "\n",
    "To create a table in a markdown cell, I recommend using the markdown table generator here: https://www.tablesgenerator.com/markdown_tables. This interface allows you to choose the number of rows and columns, fill in those rows and colums, and push the \"generate\" button. The website will display markdown table code that looks like:\n",
    "```\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "```\n",
    "Copy the markdown code and paste it into a markdown cell in your notebook. Markdown will read the code and display a table that looks like this:\n",
    "\n",
    "| Day       | Temp | Rain |\n",
    "|-----------|------|------|\n",
    "| Monday    | 74   | No   |\n",
    "| Tuesday   | 58   | Yes  |\n",
    "| Wednesday | 76   | No   |\n",
    "\n",
    "Suppose that we have (fake) data on people who were hospitalized and received at least one prescription for a medication. Here are ten records in the data:\n",
    "\n",
    "(If this table gets cut off in the PDF, please look at the .ipynb notebook file on the module 6 page on Canvas)\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | prior_conditions                     | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|--------------------------------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | [Pneumonia, Diabetes]                | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | [Pneumonia, Diabetes]                | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | [Appendicitis, Crohn's disease]      | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | [Kidney Cancer]                      | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | [Cardiomyopathy, Diabetes, Sciatica] | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | [Pancreatic Cancer, Sciatica]        | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "\n",
    "The columns in this dataset are:\n",
    "\n",
    "* **patient_name**: The patient's name\n",
    "* **date_of_birth**: The patient's date of birth\n",
    "* **prescribed_drug**: The brand name of the medication that patient has been prescribed\n",
    "* **prior_conditions**: A list of the conditions that the patient had been diagnosed with prior to the patient's hospitalization\n",
    "* **patient_sex**: The patient's sex\n",
    "* **patient_insurance**: The company responsible for the patient's health insurance coverage\n",
    "* **drug_maker**: The company that manufactures the prescribed drug\n",
    "* **drug_cost**: The cost of the prescribed drug\n",
    "* **attending_physician**: The name of the attending physician for the patient\n",
    "* **AP_medschool**: The name of the school where the attending physician got a medical degree\n",
    "* **AP_years_experience**: The attending physician's number of years of experience post-residency\n",
    "* **hospital**: The hospital where the attending physicial is employed\n",
    "* **hospital_location**: The location of the hospital\n",
    "\n",
    "For this problem, assume that \n",
    "\n",
    "1. No two rows in this table share both the same patient and the same prescribed drug.\n",
    "   \n",
    "2. Some patients in the data share the same name, but no two patients in the data share the same name and date of birth.\n",
    "\n",
    "3. No two different drugs share the same brand name.\n",
    "\n",
    "4. No two attending physicians have the same name, and every attending physician is employed at only one hospital.\n",
    "\n",
    "5. No two hospitals share the same name, and every hospital exists at only one location.\n",
    "   \n",
    "6. Each patient has only one attending physician. (In real-world applications we may want to design a database that allows for multiple hospitalizations for some patients, but here we'll keep it simpler by assuming each patient has one hospitalization with one attending physician.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Rearrange the data into a group of data tables that together meet the requirements of first normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prior_conditions                     |\n",
    "|--------------------|---------------|--------------------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Pneumonia                            |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Diabetes                             |\n",
    "| Raniero Coumans    | 8/15/1990     | Appendicitis                         |\n",
    "| Raniero Coumans    | 8/15/1990     | Crohn's disease                      |\n",
    "| Mizuki Debenham    | 3/12/1977     | Kidney Cancer                        |\n",
    "| Zoë De Witt        | 11/23/1947    | Cardiomyopathy                       |\n",
    "| Zoë De Witt        | 11/23/1947    | Diabetes                             |\n",
    "| Zoë De Witt        | 11/23/1947    | Sciatica                             |\n",
    "| Bonnie Hooper      | 7/4/1951      | Pancreatic Cancer                    |\n",
    "| Bonnie Hooper      | 7/4/1951      | Sciatica                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1NF Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | patient_sex | patient_insurance      | drug_maker               | drug_cost | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|-------------|------------------------|--------------------------|-----------|---------------------|-----------------------------------|--------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | M           | Aetna                  | USAntibiotics            | 14.62     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | M           | Aetna                  | Pfizer                   | 20.55     | Earnest Caro        | University of California (Irvine) | 14                 | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | M           | Cigna                  | Baxter International Inc | 394.00    | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | M           | Cigna                  | Abbvie                   | 7000.00   | Pamela English      | University of Michigan            | 29                 | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | F           | Kaiser Permanente      | Pfizer                   | 21644.00  | Lewis Conti         | North Carolina State University   | 8                  | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | F           | Medicare               | Mylan Pharmaceuticals    | 10.58     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | F           | Medicare               | Pfizer                   | 20.55     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | F           | Medicare               | Pfizer                   | 37.50     | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                 | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | F           | Blue Cross Blue Shield | Genentech                | 860.00    | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | F           | Blue Cross Blue Shield | Pfizer                   | 37.50     | Steven Garbutt      | Ohio State University             | 36                 | UCSF Medical Center            | San Francisco, CA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b \n",
    "Rearrange the data on the five patients into a group of data tables that together meet the requirements of second normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prior_conditions                     |\n",
    "|--------------------|---------------|--------------------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Pneumonia                            |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Diabetes                             |\n",
    "| Raniero Coumans    | 8/15/1990     | Appendicitis                         |\n",
    "| Raniero Coumans    | 8/15/1990     | Crohn's disease                      |\n",
    "| Mizuki Debenham    | 3/12/1977     | Kidney Cancer                        |\n",
    "| Zoë De Witt        | 11/23/1947    | Cardiomyopathy                       |\n",
    "| Zoë De Witt        | 11/23/1947    | Diabetes                             |\n",
    "| Zoë De Witt        | 11/23/1947    | Sciatica                             |\n",
    "| Bonnie Hooper      | 7/4/1951      | Pancreatic Cancer                    |\n",
    "| Bonnie Hooper      | 7/4/1951      | Sciatica                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient Table:\n",
    "\n",
    "| patient_name       | date_of_birth | patient_sex | patient_insurance      | \n",
    "|--------------------|---------------|-------------|------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | M           | Aetna                  |\n",
    "| Raniero Coumans    | 8/15/1990     | M           | Cigna                  |\n",
    "| Mizuki Debenham    | 3/12/1977     | F           | Kaiser Permanente      |\n",
    "| Zoë De Witt        | 11/23/1947    | F           | Medicare               |\n",
    "| Bonnie Hooper      | 7/4/1951      | F           | Blue Cross Blue Shield |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs Table:\n",
    "\n",
    "| prescribed_drug | drug_maker               | drug_cost |\n",
    "|-----------------|--------------------------|-----------|\n",
    "| Amoxil          | USAntibiotics            | 14.62     |\n",
    "| Micronase       | Pfizer                   | 20.55     |\n",
    "| Zosyn           | Baxter International Inc | 394.00    |\n",
    "| Humira          | Abbvie                   | 7000.00   |\n",
    "| Inlyta          | Pfizer                   | 21644.00  |\n",
    "| Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| Demerol         | Pfizer                   | 37.50     |\n",
    "| Xeloda          | Genentech                | 860.00    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2NF Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | attending_physician | AP_medschool                      | AP_years_experience | hospital                       | hospital_location |\n",
    "|--------------------|---------------|-----------------|---------------------|-----------------------------------|---------------------|--------------------------------|-------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | Earnest Caro        | University of California (Irvine) | 14                  | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | Earnest Caro        | University of California (Irvine) | 14                  | UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | Pamela English      | University of Michigan            | 29                  | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | Pamela English      | University of Michigan            | 29                  | Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | Lewis Conti         | North Carolina State University   | 8                   | Houston Methodist Hospital     | Houston, TX       |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  | Mount Sinai Hospital           | New York, NY      |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  | Mount Sinai Hospital           | New York, NY      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | Steven Garbutt      | Ohio State University             | 36                  | UCSF Medical Center            | San Francisco, CA |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | Steven Garbutt      | Ohio State University             | 36                  | UCSF Medical Center            | San Francisco, CA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c \n",
    "Rearrange the data into a group of data tables that together meet the requirements of third normal form. [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3NF Tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary Keys Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prescribed_drug | attending_physician |\n",
    "|--------------------|---------------|-----------------|---------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | Earnest Caro        |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | Earnest Caro        |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | Pamela English      |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | Pamela English      |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | Lewis Conti         |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | Theresa Dahlmans    |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | Theresa Dahlmans    |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | Theresa Dahlmans    |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | Steven Garbutt      |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | Steven Garbutt      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients Table:\n",
    "\n",
    "| patient_name       | date_of_birth | patient_sex | patient_insurance      | \n",
    "|--------------------|---------------|-------------|------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | M           | Aetna                  |\n",
    "| Raniero Coumans    | 8/15/1990     | M           | Cigna                  |\n",
    "| Mizuki Debenham    | 3/12/1977     | F           | Kaiser Permanente      |\n",
    "| Zoë De Witt        | 11/23/1947    | F           | Medicare               |\n",
    "| Bonnie Hooper      | 7/4/1951      | F           | Blue Cross Blue Shield |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions Table:\n",
    "\n",
    "| patient_name       | date_of_birth | prior_conditions                     |\n",
    "|--------------------|---------------|--------------------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Pneumonia                            |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Diabetes                             |\n",
    "| Raniero Coumans    | 8/15/1990     | Appendicitis                         |\n",
    "| Raniero Coumans    | 8/15/1990     | Crohn's disease                      |\n",
    "| Mizuki Debenham    | 3/12/1977     | Kidney Cancer                        |\n",
    "| Zoë De Witt        | 11/23/1947    | Cardiomyopathy                       |\n",
    "| Zoë De Witt        | 11/23/1947    | Diabetes                             |\n",
    "| Zoë De Witt        | 11/23/1947    | Sciatica                             |\n",
    "| Bonnie Hooper      | 7/4/1951      | Pancreatic Cancer                    |\n",
    "| Bonnie Hooper      | 7/4/1951      | Sciatica                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs Table:\n",
    "\n",
    "| prescribed_drug | drug_maker               | drug_cost |\n",
    "|-----------------|--------------------------|-----------|\n",
    "| Amoxil          | USAntibiotics            | 14.62     |\n",
    "| Micronase       | Pfizer                   | 20.55     |\n",
    "| Zosyn           | Baxter International Inc | 394.00    |\n",
    "| Humira          | Abbvie                   | 7000.00   |\n",
    "| Inlyta          | Pfizer                   | 21644.00  |\n",
    "| Atenolol        | Mylan Pharmaceuticals    | 10.58     |\n",
    "| Demerol         | Pfizer                   | 37.50     |\n",
    "| Xeloda          | Genentech                | 860.00    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physicians Table:\n",
    "\n",
    "| attending_physician | AP_medschool                      | AP_years_experience | hospital                       |\n",
    "|---------------------|-----------------------------------|---------------------|--------------------------------|\n",
    "| Earnest Caro        | University of California (Irvine) | 14                  | UPMC Presbyterian Shadyside    |\n",
    "| Pamela English      | University of Michigan            | 29                  | Northwestern Memorial Hospital |\n",
    "| Lewis Conti         | North Carolina State University   | 8                   | Houston Methodist Hospital     |\n",
    "| Theresa Dahlmans    | Lake Erie College of Medicine     | 17                  | Mount Sinai Hospital           |\n",
    "| Steven Garbutt      | Ohio State University             | 36                  | UCSF Medical Center            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hospitals Table:\n",
    "\n",
    "| hospital                       | hospital_location |\n",
    "|--------------------------------|-------------------|\n",
    "| UPMC Presbyterian Shadyside    | Pittsburgh, PA    |\n",
    "| Northwestern Memorial Hospital | Chicago, IL       |\n",
    "| Houston Methodist Hospital     | Houston, TX       |\n",
    "| Mount Sinai Hospital           | New York, NY      |\n",
    "| UCSF Medical Center            | San Francisco, CA |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "For this problem, create ER diagrams of the database you created in problem 1, part c using https://dbdocs.io/. Make sure you install DBDocs on your system by following these instructions: https://dbdocs.io/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a \n",
    "Write code using the [database markup language](https://dbml.dbdiagram.io/home/) (DBML) that represents all of the tables in this database and the connections between the tables. Paste your DBML code in a markdown cell in your notebook, contained within three backticks to begin and end the code snippet, as shown in the cell below. \n",
    "\n",
    "Two good resources to help you:\n",
    "\n",
    "1. The example on the Getting Started page on dbdocs.io: https://dbdocs.io/docs\n",
    "2. The full syntax guide for DBML: https://dbml.dbdiagram.io/docs/#project-definition\n",
    "\n",
    "A few notes:\n",
    "* Make sure to specify the data type for each column in each table. Use varchar for strings/text, int for integers, and float for numeric data with decimals.\n",
    "* You will probably find it useful to alias each table with one or two letters, such as: Table PRESCRIPTIONS as PR. That will allow you to use PR to refer to the PRESCRIPTIONS table, for example, in the Reference statements to link tables together.\n",
    "* Use the syntax [pk] after a column name and data type to designate the columns that are primary keys in each table.\n",
    "* To draw the lines linking one table to another, use the Ref: syntax.\n",
    "    * If many rows from the left table match to one row in the right table, use the \"many to one\" symbol >\n",
    "    * If one row from the left table matches to many rows in the right table, use the \"one to many\" symbol <\n",
    "    * If one row from the left table matches to one row in the right table, use the \"one to one\" symbol -\n",
    "    * If many rows from the left table match to many rows in the right table, use the \"many to many\" symbol <>\n",
    "      \n",
    "[2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_keys = pd.read_csv('primary_key.csv')\n",
    "patients = pd.read_csv('patient.csv')\n",
    "conditions = pd.read_csv('conditions.csv')\n",
    "drugs = pd.read_csv('drugs.csv')\n",
    "physicians = pd.read_csv('physician.csv')\n",
    "hospitals = pd.read_csv('hospital.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Make sure you get the .ipynb file for this lab from the module 6 page on Canvas\n",
    "\n",
    "Then when you double-click this box, you'll see three backticks before and after this text. Leave those alone\n",
    "\n",
    "Type your code here, between the backticks\n",
    "\n",
    "Code:\n",
    "\n",
    "Project MedicalRecords {\n",
    "  database_type: 'PostgreSQL'\n",
    "  Note: '''\n",
    "    # Patient Records\n",
    "    **Database created for patient records, July 2024**\n",
    "  '''\n",
    "}\n",
    "Table primary_keys as PK {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  prescribed_drug varchar [pk]\n",
    "  attending_physician varchar\n",
    "  note: \"table 'primary_keys' contains the primary keys\"\n",
    "}\n",
    "Table patients as P {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  patient_sex varchar\n",
    "  patient_insurance varchar\n",
    "  note: \"table 'patients' contains information about patients and their health insurance\"\n",
    "}\n",
    "Table conditions as C {\n",
    "  patient_name varchar [pk]\n",
    "  date_of_birth varchar [pk]\n",
    "  prior_conditions varchar [pk]\n",
    "  note: \"table 'conditions' contains information about existing conditions within patients\"\n",
    "}\n",
    "Table drugs as D {\n",
    "  prescribed_drug varchar [pk]\n",
    "  drug_maker varchar\n",
    "  drug_cost float\n",
    "  note: \"table 'drugs' contains information about the drug makers and their costs\"\n",
    "}\n",
    "Table physicians as PH {\n",
    "  attending_physician varchar [pk]\n",
    "  AP_medschool varchar\n",
    "  AP_years_experience int\n",
    "  hospital varchar\n",
    "  note: \"table 'physicians' contains information about the physicians and their work experience\"\n",
    "}\n",
    "Table hospitals as H {\n",
    "  hospital varchar [pk]\n",
    "  hospital_location varchar\n",
    "  note: \"table 'hospitals' contains information about the hospitals and their locations\"\n",
    "}\n",
    "\n",
    "Ref: D.prescribed_drug < PK.prescribed_drug\n",
    "Ref: PH.attending_physician < PK.attending_physician\n",
    "Ref: P.patient_name < PK.patient_name\n",
    "Ref: P.date_of_birth < PK.date_of_birth\n",
    "Ref: C.patient_name - PK.patient_name\n",
    "Ref: C.date_of_birth - PK.date_of_birth\n",
    "Ref: PH.hospital - H.hospital \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the instructions on DBDocs.io (https://dbdocs.io/docs) to create a website for your ER diagram. Type the URL for your website in a markdown cell here. [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My example is here: https://dbdocs.io/jkropko/Lab6?view=relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL: https://dbdocs.io/kl2jmx/MedicalRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "For this problem, you will download the individual CSV files that comprise a relational database on album reviews from [Pitchfork Magazine](https://pitchfork.com/), collected via webscraping by [Nolan B. Conaway](https://github.com/nolanbconaway/pitchfork-data), and use them to initialize local databases using SQlite, MySQL, and PostgreSQL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code of code will download the CSV files. Please run this as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/nolanbconaway/pitchfork-data/raw/master/pitchfork.db\"\n",
    "pfork = wget.download(url)\n",
    "pitchfork = sqlite3.connect(pfork)\n",
    "for t in ['artists','content','genres','labels','reviews','years']:\n",
    "    datatable = pd.read_sql_query(\"SELECT * FROM {tab}\".format(tab=t), pitchfork)\n",
    "    datatable.to_csv(\"{tab}.csv\".format(tab=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this code downloaded a SQlite database and extracted the tables, saving each one as a CSV. That seems backwards, as the purpose of this exercise is to create databases. But the point here is to practice creating databases from individual data frames. Next we load the CSVs to create the data frames in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "artists = pd.read_csv(\"artists.csv\")\n",
    "content = pd.read_csv(\"content.csv\")\n",
    "genres = pd.read_csv(\"genres.csv\")\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "years = pd.read_csv(\"years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a\n",
    "Initialize a new database using SQlite and the `sqlite3` library. Add the six dataframes to this database. Then issue the following query to the database\n",
    "```\n",
    "SELECT title, artist, score FROM reviews WHERE score=10\n",
    "```\n",
    "using two methods: first, using the `.cursor()` method, and second using `pd.read_sql_query()`. Finally, commit your changes to the database and close the database. (If you get a warning about spaces in the column names, feel free to ignore it this time.) [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New database\n",
    "new_db = sqlite3.connect('pitchfork_a.db')\n",
    "\n",
    "# Dataframes\n",
    "reviews.to_sql('reviews', new_db, if_exists = 'replace', index = False)\n",
    "artists.to_sql('artists', new_db, if_exists = 'replace', index = False)\n",
    "content.to_sql('content', new_db, if_exists = 'replace', index = False)\n",
    "genres.to_sql('genres', new_db, if_exists = 'replace', index = False)\n",
    "labels.to_sql('labels', new_db, if_exists = 'replace', index = False)\n",
    "years.to_sql('years', new_db, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('metal box', 'public image ltd', 10.0)\n",
      "('blood on the tracks', 'bob dylan', 10.0)\n",
      "('another green world', 'brian eno', 10.0)\n",
      "('songs in the key of life', 'stevie wonder', 10.0)\n",
      "('in concert', 'nina simone', 10.0)\n",
      "(\"tonight's the night\", 'neil young', 10.0)\n",
      "('hounds of love', 'kate bush', 10.0)\n",
      "('sign \"o\" the times', 'prince', 10.0)\n",
      "('1999', 'prince', 10.0)\n",
      "('purple rain', 'prince, the revolution', 10.0)\n",
      "('dirty mind', 'prince', 10.0)\n",
      "('off the wall', 'michael jackson', 10.0)\n",
      "('\"heroes\"', 'david bowie', 10.0)\n",
      "('low', 'david bowie', 10.0)\n",
      "('a love supreme: the complete masters', 'john coltrane', 10.0)\n",
      "(\"people's instinctive travels and the paths of rhythm\", 'a tribe called quest', 10.0)\n",
      "('astral weeks', 'van morrison', 10.0)\n",
      "('loaded: re-loaded 45th anniversary edition', 'the velvet underground', 10.0)\n",
      "('sticky fingers', 'the rolling stones', 10.0)\n",
      "('it takes a nation of millions to hold us back', 'public enemy', 10.0)\n",
      "('the velvet underground  45th anniversary super deluxe edition', 'the velvet underground', 10.0)\n",
      "('spiderland', 'slint', 10.0)\n",
      "('the infamous', 'mobb deep', 10.0)\n",
      "('white light/white heat', 'the velvet underground', 10.0)\n",
      "('in utero: 20th anniversary edition', 'nirvana', 10.0)\n",
      "('rumours', 'fleetwood mac', 10.0)\n",
      "('illmatic', 'nas', 10.0)\n",
      "('donuts (45 box set)', 'j dilla', 10.0)\n",
      "('voodoo', 'dangelo', 10.0)\n",
      "('the disintegration loops', 'william basinski', 10.0)\n",
      "('liquid swords: chess box deluxe edition', 'gza', 10.0)\n",
      "(\"isn't anything\", 'my bloody valentine', 10.0)\n",
      "('tago mago [40th anniversary edition]', 'can', 10.0)\n",
      "('the smile sessions', 'the beach boys', 10.0)\n",
      "('laughing stock', 'talk talk', 10.0)\n",
      "('nevermind [20th anniversary edition]', 'nirvana', 10.0)\n",
      "('emergency & i [vinyl reissue]', 'the dismemberment plan', 10.0)\n",
      "('my beautiful dark twisted fantasy', 'kanye west', 10.0)\n",
      "('disintegration [deluxe edition]', 'the cure', 10.0)\n",
      "('exile on main st. [deluxe edition]', 'the rolling stones', 10.0)\n",
      "('quarantine the past', 'pavement', 10.0)\n",
      "(\"ladies and gentlemen we are floating in space [collector's editon]\", 'spiritualized', 10.0)\n",
      "('the stone roses', 'the stone roses', 10.0)\n",
      "('the beatles', 'the beatles', 10.0)\n",
      "('abbey road', 'the beatles', 10.0)\n",
      "('rubber soul', 'the beatles', 10.0)\n",
      "('revolver', 'the beatles', 10.0)\n",
      "(\"sgt. pepper's lonely hearts club band\", 'the beatles', 10.0)\n",
      "('magical mystery tour', 'the beatles', 10.0)\n",
      "('stereo box', 'the beatles', 10.0)\n",
      "('kid a: special collectors edition', 'radiohead', 10.0)\n",
      "('reckoning [deluxe edition]', 'r.e.m.', 10.0)\n",
      "('histoire de melody nelson', 'serge gainsbourg', 10.0)\n",
      "(\"paul's boutique\", 'beastie boys', 10.0)\n",
      "('murmur [deluxe edition]', 'r.e.m.', 10.0)\n",
      "(\"otis blue: otis redding sings soul [collector's edition]\", 'otis redding', 10.0)\n",
      "('unknown pleasures', 'joy division', 10.0)\n",
      "('daydream nation: deluxe edition', 'sonic youth', 10.0)\n",
      "('pink flag', 'wire', 10.0)\n",
      "('born to run: 30th anniversary edition', 'bruce springsteen', 10.0)\n",
      "('in the aeroplane over the sea', 'neutral milk hotel', 10.0)\n",
      "('endtroducing... [deluxe edition]', 'dj shadow', 10.0)\n",
      "(\"crooked rain, crooked rain: la's desert origins\", 'pavement', 10.0)\n",
      "('london calling: 25th anniversary legacy edition', 'the clash', 10.0)\n",
      "('music has the right to children', 'boards of canada', 10.0)\n",
      "('live at the apollo [expanded edition]', 'james brown', 10.0)\n",
      "('no thanks!: the 70s punk rebellion', 'various artists', 10.0)\n",
      "('marquee moon', 'television', 10.0)\n",
      "('the ascension', 'glenn branca', 10.0)\n",
      "(\"this year's model\", 'elvis costello & the attractions', 10.0)\n",
      "('yankee hotel foxtrot', 'wilco', 10.0)\n",
      "('source tags and codes', '...and you will know us by the trail of dead', 10.0)\n",
      "('the olatunji concert: the last live recording', 'john coltrane', 10.0)\n",
      "('kid a', 'radiohead', 10.0)\n",
      "('animals', 'pink floyd', 10.0)\n",
      "('i see a darkness', 'bonnie prince billy', 10.0)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: .cursor()\n",
    "cursor = new_db.cursor()\n",
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score = 10\")\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Showing results\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title  \\\n",
      "0                                       metal box   \n",
      "1                             blood on the tracks   \n",
      "2                             another green world   \n",
      "3                        songs in the key of life   \n",
      "4                                      in concert   \n",
      "..                                            ...   \n",
      "71                          source tags and codes   \n",
      "72  the olatunji concert: the last live recording   \n",
      "73                                          kid a   \n",
      "74                                        animals   \n",
      "75                               i see a darkness   \n",
      "\n",
      "                                          artist  score  \n",
      "0                               public image ltd   10.0  \n",
      "1                                      bob dylan   10.0  \n",
      "2                                      brian eno   10.0  \n",
      "3                                  stevie wonder   10.0  \n",
      "4                                    nina simone   10.0  \n",
      "..                                           ...    ...  \n",
      "71  ...and you will know us by the trail of dead   10.0  \n",
      "72                                 john coltrane   10.0  \n",
      "73                                     radiohead   10.0  \n",
      "74                                    pink floyd   10.0  \n",
      "75                           bonnie prince billy   10.0  \n",
      "\n",
      "[76 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Method 2: pd.read_sql_query()\n",
    "query = \"SELECT title, artist, score FROM reviews WHERE score = 10\"\n",
    "results_df = pd.read_sql_query(query, new_db)\n",
    "\n",
    "# Showing results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes and close database\n",
    "new_db.commit()\n",
    "new_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "Follow the instructions in the Jupyter notebook for this module to install MySQL and `mysql.connector` on your computer. Make sure the MySQL server is running. Then import `mysql.connector` and do all of the tasks listed for part a using a MySQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector\n",
      "  Downloading mysql-connector-2.2.9.tar.gz (11.9 MB)\n",
      "     ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/11.9 MB 131.3 kB/s eta 0:01:31\n",
      "     --------------------------------------- 0.0/11.9 MB 131.3 kB/s eta 0:01:31\n",
      "     --------------------------------------- 0.0/11.9 MB 119.1 kB/s eta 0:01:40\n",
      "     --------------------------------------- 0.0/11.9 MB 119.1 kB/s eta 0:01:40\n",
      "     --------------------------------------- 0.0/11.9 MB 119.1 kB/s eta 0:01:40\n",
      "     --------------------------------------- 0.0/11.9 MB 103.4 kB/s eta 0:01:55\n",
      "     --------------------------------------- 0.0/11.9 MB 103.4 kB/s eta 0:01:55\n",
      "     --------------------------------------- 0.1/11.9 MB 126.1 kB/s eta 0:01:34\n",
      "     --------------------------------------- 0.1/11.9 MB 158.2 kB/s eta 0:01:15\n",
      "     --------------------------------------- 0.1/11.9 MB 168.9 kB/s eta 0:01:10\n",
      "     --------------------------------------- 0.1/11.9 MB 168.9 kB/s eta 0:01:10\n",
      "     --------------------------------------- 0.1/11.9 MB 181.9 kB/s eta 0:01:05\n",
      "     --------------------------------------- 0.1/11.9 MB 180.2 kB/s eta 0:01:06\n",
      "      -------------------------------------- 0.2/11.9 MB 223.3 kB/s eta 0:00:53\n",
      "      -------------------------------------- 0.2/11.9 MB 250.8 kB/s eta 0:00:47\n",
      "      -------------------------------------- 0.2/11.9 MB 275.3 kB/s eta 0:00:43\n",
      "      -------------------------------------- 0.2/11.9 MB 275.3 kB/s eta 0:00:43\n",
      "      -------------------------------------- 0.2/11.9 MB 269.2 kB/s eta 0:00:44\n",
      "      -------------------------------------- 0.3/11.9 MB 271.3 kB/s eta 0:00:43\n",
      "     - ------------------------------------- 0.3/11.9 MB 311.6 kB/s eta 0:00:38\n",
      "     - ------------------------------------- 0.4/11.9 MB 363.9 kB/s eta 0:00:32\n",
      "     - ------------------------------------- 0.4/11.9 MB 401.0 kB/s eta 0:00:29\n",
      "     - ------------------------------------- 0.5/11.9 MB 446.5 kB/s eta 0:00:26\n",
      "     - ------------------------------------- 0.5/11.9 MB 446.5 kB/s eta 0:00:26\n",
      "     - ------------------------------------- 0.5/11.9 MB 419.4 kB/s eta 0:00:28\n",
      "     - ------------------------------------- 0.5/11.9 MB 434.1 kB/s eta 0:00:27\n",
      "     -- ------------------------------------ 0.7/11.9 MB 517.7 kB/s eta 0:00:22\n",
      "     -- ------------------------------------ 0.8/11.9 MB 592.1 kB/s eta 0:00:19\n",
      "     --- ----------------------------------- 0.9/11.9 MB 685.7 kB/s eta 0:00:16\n",
      "     --- ----------------------------------- 1.0/11.9 MB 729.8 kB/s eta 0:00:15\n",
      "     --- ----------------------------------- 1.0/11.9 MB 729.8 kB/s eta 0:00:15\n",
      "     --- ----------------------------------- 1.0/11.9 MB 682.7 kB/s eta 0:00:16\n",
      "     --- ----------------------------------- 1.2/11.9 MB 756.5 kB/s eta 0:00:15\n",
      "     ---- ---------------------------------- 1.4/11.9 MB 871.3 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.6/11.9 MB 985.8 kB/s eta 0:00:11\n",
      "     ------ --------------------------------- 1.9/11.9 MB 1.1 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 2.1/11.9 MB 1.2 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 2.1/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 2.1/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 2.3/11.9 MB 1.3 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 2.8/11.9 MB 1.5 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 3.2/11.9 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 3.7/11.9 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.1/11.9 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.2/11.9 MB 2.1 MB/s eta 0:00:04\n",
      "     -------------- ------------------------- 4.3/11.9 MB 2.0 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 4.9/11.9 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 5.7/11.9 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 6.7/11.9 MB 3.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 7.9/11.9 MB 3.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 8.4/11.9 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 8.4/11.9 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.1/11.9 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 10.4/11.9 MB 6.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.7/11.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  11.8/11.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 11.9/11.9 MB 11.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: mysql-connector\n",
      "  Building wheel for mysql-connector (setup.py): started\n",
      "  Building wheel for mysql-connector (setup.py): finished with status 'done'\n",
      "  Created wheel for mysql-connector: filename=mysql_connector-2.2.9-cp312-cp312-win_amd64.whl size=247958 sha256=23872947c9da3578a5e155b209bdc09350488d0f77cad10358b5c4fc8b218999\n",
      "  Stored in directory: c:\\users\\leeka\\appdata\\local\\pip\\cache\\wheels\\03\\17\\fa\\d7604c72dd3dd6d3eb3d249abf36cc532c9a9b4354b8f1bc4f\n",
      "Successfully built mysql-connector\n",
      "Installing collected packages: mysql-connector\n",
      "Successfully installed mysql-connector-2.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\leeka\\miniconda3\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:334\u001b[0m, in \u001b[0;36mCMySQLConnection._open_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcnx_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mconverter_str_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_converter_str_fallback\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Access denied for user 'root'@'localhost' (using password: YES)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mysql_password \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMYSQL_ROOT_PASSWORD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Connect to server\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dbserver \u001b[38;5;241m=\u001b[39m \u001b[43mmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmysql_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leeka\\miniconda3\\Lib\\site-packages\\mysql\\connector\\pooling.py:322\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(ERROR_NO_CEXT)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CMySQLConnection \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_pure:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCMySQLConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MySQLConnection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leeka\\miniconda3\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:151\u001b[0m, in \u001b[0;36mCMySQLConnection.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\leeka\\miniconda3\\Lib\\site-packages\\mysql\\connector\\abstracts.py:1399\u001b[0m, in \u001b[0;36mMySQLConnectionAbstract.connect\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect()\n\u001b[1;32m-> 1399\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1401\u001b[0m charset, collation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1402\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1403\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1404\u001b[0m )\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m charset \u001b[38;5;129;01mor\u001b[39;00m collation:\n",
      "File \u001b[1;32mc:\\Users\\leeka\\miniconda3\\Lib\\site-packages\\mysql\\connector\\connection_cext.py:339\u001b[0m, in \u001b[0;36mCMySQLConnection._open_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter\u001b[38;5;241m.\u001b[39mstr_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_converter_str_fallback\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    340\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[0;32m    341\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_handshake()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_disabled\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_ssl_cipher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m# `get_ssl_cipher()` returns the name of the cipher being used.\u001b[39;00m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)"
     ]
    }
   ],
   "source": [
    "# Environmental variables\n",
    "dotenv.load_dotenv()\n",
    "mysql_password = os.getenv('MYSQL_ROOT_PASSWORD')\n",
    "\n",
    "# Connect to server\n",
    "dbserver = mysql.connector.connect(user = 'root',\n",
    "                                    password = mysql_password,\n",
    "                                    host = 'localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Database\n",
    "cursor = dbserver.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE pitchfork_b')\n",
    "except:\n",
    "    cursor.execute('DROP DATABASE pitchfork_b')\n",
    "    cursor.execute('CREATE DATABASE pitchfork_b')\n",
    "\n",
    "# Connect to database\n",
    "new_db2 = mysql.connector.connect(user = 'root',\n",
    "                                     password = mysql_password,\n",
    "                                     host = 'localhost',\n",
    "                                     database = 'pitchfork_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "engine = create_engine(\"mysql+mysqlconnector://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"root\", pw=mysql_password, db=\"pitchfork_b\"))\n",
    "\n",
    "reviews.to_sql('reviews', engine, if_exists = 'replace', index = False)\n",
    "artists.to_sql('artists', engine, if_exists = 'replace', index = False)\n",
    "content.to_sql('content', engine, if_exists = 'replace', index = False)\n",
    "genres.to_sql('genres', engine, if_exists = 'replace', index = False)\n",
    "labels.to_sql('labels', engine, if_exists = 'replace', index = False)\n",
    "years.to_sql('years', engine, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: .cursor()\n",
    "cursor = connections.cursor()\n",
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score = 10\")\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Showing results\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: pd.read_sql_query()\n",
    "query = \"SELECT title, artist, score FROM reviews WHERE score = 10\"\n",
    "results_df = pd.read_sql_query(query, connections)\n",
    "\n",
    "# Showing results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes and close database\n",
    "connections.commit()\n",
    "connections.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Follow the instructions in the Jupyter notebook for this module to install PostgreSQL and `psycopg2` on your computer. Then import `psycopg2` and do all of the tasks listed for part a using a PostgreSQL database (including commiting changes and closing the database connection). Take steps to hide your password - do not let it display in your notebook. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environmental variables\n",
    "dotenv.load_dotenv()\n",
    "postgres_password = os.getenv('POSTGRES_PASSWORD')\n",
    "\n",
    "# Connect to server\n",
    "dbserver = psycopg.connect(\n",
    "    user = 'postgres',\n",
    "    password = postgres_password,\n",
    "    host = 'localhost',\n",
    "    port = '5432'\n",
    ")\n",
    "\n",
    "dbserver.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New database\n",
    "cursor = dbserver.cursor()\n",
    "\n",
    "try:\n",
    "    cursor.execute('CREATE DATABASE pitchfork_c')\n",
    "except:\n",
    "    cursor.execute('DROP DATABASE pitchfork_c')\n",
    "    cursor.execute('CREATE DATABASE pitchfork_c')\n",
    "\n",
    "dbms = 'postgresql'\n",
    "connector = 'psycopg'\n",
    "user = 'postgres'\n",
    "password = postgres_password\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "database = 'pitchfork_c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "engine_string = f'{dbms}+{connector}://{user}:{password}@{host}:{port}/{database}'\n",
    "engine2 = create_engine(engine_string)\n",
    "\n",
    "reviews.to_sql('reviews', engine2, if_exists = 'replace', index = False)\n",
    "artists.to_sql('artists', engine2, if_exists = 'replace', index = False)\n",
    "content.to_sql('content', engine2, if_exists = 'replace', index = False)\n",
    "genres.to_sql('genres', engine2, if_exists = 'replace', index = False)\n",
    "labels.to_sql('labels', engine2, if_exists = 'replace', index = False)\n",
    "years.to_sql('years', engine2, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: .cursor()\n",
    "cursor = connections.cursor()\n",
    "cursor.execute(\"SELECT title, artist, score FROM reviews WHERE score = 10\")\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Showing results\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: pd.read_sql_query()\n",
    "query = \"SELECT title, artist, score FROM reviews WHERE score = 10\"\n",
    "results_df = pd.read_sql_query(query, connections)\n",
    "\n",
    "# Showing results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit changes and close database\n",
    ".commit()\n",
    ".close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "[Colin Mitchell](http://muffinlabs.com/) is a web-developer and artist who has a bunch of [cool projects](http://muffinlabs.com/projects.html) that play with what data can do on the internet. One of his projects is [Today in History](https://history.muffinlabs.com/), which provides an API to access all the Wikipedia pages for historical events that happened on this day in JSON format. The records in this JSON are stored in the `['data']['events']` path. Here's the first listing for today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '180',\n",
       " 'text': 'Twelve inhabitants of Scillium (near Kasserine, modern-day Tunisia) in North Africa are executed for being Christians. This is the earliest record of Christianity in that part of the world.',\n",
       " 'html': '180 - <a href=\"https://wikipedia.org/wiki/Scillitan_Martyrs\" title=\"Scillitan Martyrs\">Twelve inhabitants</a> of <a href=\"https://wikipedia.org/wiki/Scillium\" title=\"Scillium\">Scillium</a> (near Kasserine, modern-day <a href=\"https://wikipedia.org/wiki/Tunisia\" title=\"Tunisia\">Tunisia</a>) in North Africa are executed for being Christians. This is the earliest record of Christianity in that part of the world.',\n",
       " 'no_year_html': '<a href=\"https://wikipedia.org/wiki/Scillitan_Martyrs\" title=\"Scillitan Martyrs\">Twelve inhabitants</a> of <a href=\"https://wikipedia.org/wiki/Scillium\" title=\"Scillium\">Scillium</a> (near Kasserine, modern-day <a href=\"https://wikipedia.org/wiki/Tunisia\" title=\"Tunisia\">Tunisia</a>) in North Africa are executed for being Christians. This is the earliest record of Christianity in that part of the world.',\n",
       " 'links': [{'title': 'Scillitan Martyrs',\n",
       "   'link': 'https://wikipedia.org/wiki/Scillitan_Martyrs'},\n",
       "  {'title': 'Scillium', 'link': 'https://wikipedia.org/wiki/Scillium'},\n",
       "  {'title': 'Tunisia', 'link': 'https://wikipedia.org/wiki/Tunisia'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, you will use MongoDB and the `pymongo` library to create a local document store NoSQL database containing these historical events.\n",
    "\n",
    "Follow the instructions in the Jupyter notebook for this module to install MongoDB and `pymongo` on your computer. Make sure the local MongoDB server is running. Then import `pymongo`, connect to the local MongoDB client, create a database named \"history\" and a collection within that database named \"today\". Insert all of the records in `events` into this collection. Then issue the following query to find all of the records whose text contain the word \"Virginia\":\n",
    "```\n",
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'Virginia'\n",
    "    }\n",
    "}\n",
    "```\n",
    "If there are no results that contain the word \"Virginia\", choose a different work like \"England\" or \"China\". Display the count of the number of documents that match this query, display the output of the query, and generate a JSON formatted variable containing the output. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 [No points, no need to write anything here, but do it anyway!]\n",
    "When you are done working, go to the same terminal window you used to launch the databases with `docker compose up`. Here, type CONTROL + C on your keyboard to shut down the container.\n",
    "\n",
    "Next type\n",
    "```\n",
    "docker compose down\n",
    "```\n",
    "This step removes extra database software, networks, volumes, etc. running on your computer. If you don't need them, don't clog your computer.\n",
    "\n",
    "Whenever you need to work with databases, return to the terminal, navigate to this folder and type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "to bring all these resources back online. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
